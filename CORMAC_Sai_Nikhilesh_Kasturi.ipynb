{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For this exercise, I have created dummy data for procedure attirbutes, procedure success and procedure outcomes. While creating, I have made sure that there are missing values in the data, which is similar to the real world data. As, I am not very experienced in the Procedures and its nomenclature, I have assumed only the following features into my dataset. **\n",
    "\n",
    "\n",
    "**Data Dictionary**\n",
    "\n",
    "\n",
    "Procedure_attributes:\n",
    "1. Procedure_ID : Unique for every record. (Primary Key)\n",
    "2. Procedure : I taken few examples from wikipedia about types of procedures and used those. I have used around 13 different procedures.\n",
    "3. Time( in hours) : Time taken to complete the procedure.\n",
    "4. Severity : Serverity of the Procedure. ( Have 4 categories : Low, Medium, High and Nulls)\n",
    "5. Gender : Gender of the Patient undergoing procedure. ( Male, Female, Nulls)\n",
    "6. Anesthesia : Was the patient administried with Anesthesia (Yes, No)\n",
    "7. Diabetes : Does the patient has diabetes or not. (Yes, No, Nulls)\n",
    "\n",
    "Procedure_success:\n",
    "\n",
    "1. Procedure_ID : Unique for every record. (Primary Key)\n",
    "2. Outcome : For every procedure, what is the outcome ?\n",
    "\n",
    "\n",
    "Procedure_outcomes:\n",
    "\n",
    "1. Procedure_ID :  Unique for every record. (Primary Key)\n",
    "2. Severity of post procedure complications : Does the patient has any complications after procedure. (High, Low, Nulls)\n",
    "3. Recurrence of original condition : Does the patient has recurred with the original condition. (Yes, No, Nulls)\n",
    "4. Pain : Does the patient has pain after the procedure. (Yes, No, Nulls)\n",
    "\n",
    "\n",
    "Link to my Github respository : https://github.com/Nikhileshorg/CMS_data\n",
    "\n",
    "Based on the problem statment given, this is a classification type of problem. I have choosen xgb as the algorithm and Hyperopt as the optimization technique. I have tried Lightgbm as well but due to less data, it was not giving good accuracy scores. Based on the dataset. This is a classification type of problem.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Importing the required libraries\n",
    "\n",
    "import pandas as pd ###pandas\n",
    "import numpy as np  ###numpy\n",
    "import json\n",
    "import urllib    ###urlib for retrieving data from a url\n",
    "import requests  ###requests\n",
    "from scipy import interp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  ###for visualizations\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###In this cell, I have created dummy functions for get_procedure_attributes, get_procedure_success and get_procedure_outcomes.\n",
    "\n",
    "'''\n",
    "import requests\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "#####fetching the data from an API using get() method.\n",
    "response_get_procedure_attributes = requests.get(\"api.json\")  ###API will be changed accordingly for get_procedure_attributes\n",
    "response_get_procedure_success = requests.get(\"api.json\")     ###API will be changed accordingly for get_procedure_success\n",
    "response_get_procedure_outcomes = requests.get(\"api.json\")    ###API will be changed accordingly for get_procedure_outcomes\n",
    "\n",
    "\n",
    "###printing the response status from each API\n",
    "print(response_get_procedure_attributes.status_code)\n",
    "print(response_get_procedure_success.status_code)\n",
    "print(response_get_procedure_outcomes.status_code)\n",
    "\n",
    "###If everything is working fine, we should get status as 200\n",
    "\n",
    "\n",
    "####Below code is for parameter control in the API url or in the function\n",
    "\n",
    "import json\n",
    "\n",
    "def get_procedure_attributes(obj):\n",
    "    # create a formatted string of the Python JSON object\n",
    "    text = json.dumps(obj, sort_keys=True, indent=4)\n",
    "    print(text)\n",
    "    \n",
    "def get_procedure_success(obj):\n",
    "    # create a formatted string of the Python JSON object\n",
    "    text = json.dumps(obj, sort_keys=True, indent=4)\n",
    "    print(text)\n",
    "    \n",
    "def get_procedure_outcomes(obj):\n",
    "    # create a formatted string of the Python JSON object\n",
    "    text = json.dumps(obj, sort_keys=True, indent=4)\n",
    "    print(text)\n",
    "\n",
    "\n",
    "####Here we can control the parameters in each request, for example as stated we can fetch data for only Procedure = 5\n",
    "\n",
    "parameters = {\n",
    "  procedure_id = procedure_id\n",
    "}\n",
    "\n",
    "\n",
    "###Here you can see that parameters are being called in the get() method.\n",
    "response = requests.get(\"get_procedure_attributes\", params=parameters)\n",
    "\n",
    "\n",
    "###Fetches the data with given parameters\n",
    "get_procedure_attributes(response.json())\n",
    "\n",
    "###This gives output as a form of dictionary as asked in the Problem statement.\n",
    "'''\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:31: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((499, 7), (499, 2), (499, 4))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####In this cell, I have created functions for get_procedure_attributes, get_procedure_success, get_procedure_outcomes sepearely to fetch data from my Github repository.\n",
    "\n",
    "\n",
    "#####Functions for procedure attributes, procedure scuccess and procedure outcomes\n",
    "class preprocessing:\n",
    "\n",
    "      def get_procedure_attributes(self,url,colname):\n",
    "        \n",
    "        urllib.request.urlretrieve(url, \"Procedure_attributes.csv\")\n",
    "        pro_data = pd.read_csv(\"Procedure_attributes.csv\",skiprows = 0,sep='delimiter',header = None)\n",
    "        pro_data.rename(columns={0: 'Name'}, inplace=True)\n",
    "        pro_data = pro_data['Name'].str.split(',',expand = True)\n",
    "        pro_data.columns = pro_data.iloc[0]\n",
    "        pro_data = pro_data[1:]\n",
    "        return pro_data\n",
    "    \n",
    "      def get_procedure_success(self,url,colname):\n",
    "        \n",
    "        urllib.request.urlretrieve(url, \"Procedure_results.csv\")\n",
    "        pro_results = pd.read_csv(\"Procedure_results.csv\",skiprows = 0,sep='delimiter',header = None)\n",
    "        pro_results.rename(columns={0: 'Name'}, inplace=True)\n",
    "        pro_results = pro_results['Name'].str.split(',',expand = True)\n",
    "        pro_results.columns = pro_results.iloc[0]\n",
    "        pro_results = pro_results[1:]\n",
    "        return pro_results\n",
    "    \n",
    "    \n",
    "      def get_procedure_outcomes(self,url,colname):\n",
    "        \n",
    "        urllib.request.urlretrieve(url, \"Procedure_outcomes.csv\")\n",
    "        pro_outcomes = pd.read_csv(\"Procedure_outcomes.csv\",skiprows = 0,sep='delimiter',header = None)\n",
    "        pro_outcomes.rename(columns={0: 'Name'}, inplace=True)\n",
    "        pro_outcomes = pro_outcomes['Name'].str.split(',',expand = True)\n",
    "        pro_outcomes.columns = pro_outcomes.iloc[0]\n",
    "        pro_outcomes = pro_outcomes[1:]\n",
    "        return pro_outcomes\n",
    "\n",
    "####These are public URL's through which I am fetching the data. (My GIthub repository)\n",
    "\n",
    "url_new = {\n",
    "    'url_prod_attributes' :\"https://raw.githubusercontent.com/Nikhileshorg/CMS_data/main/Procedure_attributes.csv\",\n",
    "    'url_prod_results' : \"https://raw.githubusercontent.com/Nikhileshorg/CMS_data/main/Procedure_results.csv\",\n",
    "   \"url_prod_outcomes\" : \"https://raw.githubusercontent.com/Nikhileshorg/CMS_data/main/Procedure_outcomes.csv\"\n",
    "}     \n",
    "\n",
    "\n",
    "getdata = preprocessing()\n",
    "pro_data = getdata.get_procedure_attributes(url_new['url_prod_attributes'],'pro_data')\n",
    "pro_results = getdata.get_procedure_success(url_new['url_prod_results'],'pro_results')\n",
    "pro_outcomes = getdata.get_procedure_outcomes(url_new['url_prod_outcomes'],'pro_outcomes')\n",
    "\n",
    "\n",
    "###Printing the shape of the all the dataset fetched\n",
    "pro_data.shape, pro_results.shape,pro_outcomes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>procedure_id</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Procedure</th>\n",
       "      <th>Time in Hours</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>anesthesia</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>AAA Repair</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>Pancreatic Resection_Cancer</td>\n",
       "      <td>1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 procedure_id Outcome                    Procedure Time in Hours Severity  \\\n",
       "0            1    TRUE                   AAA Repair             3      Low   \n",
       "1            2    TRUE  Pancreatic Resection_Cancer             1   Medium   \n",
       "\n",
       "0  Gender anesthesia diabetes  \n",
       "0    Male        Yes      Yes  \n",
       "1  Female        Yes       No  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####In this cell, Merging the data from the function get_procedure_attributes and function get_procedure_success , procedure_id being the primary key\n",
    "Procedure_info = pd.merge(pro_results,pro_data, on = ['procedure_id'], how = 'inner')\n",
    "print(Procedure_info.shape)\n",
    "Procedure_info.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>procedure_id</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Procedure</th>\n",
       "      <th>Time in Hours</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>anesthesia</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>severity of post procedure complications</th>\n",
       "      <th>Pain</th>\n",
       "      <th>recurrence of original condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>AAA Repair</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>Pancreatic Resection_Cancer</td>\n",
       "      <td>1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 procedure_id Outcome                    Procedure Time in Hours Severity  \\\n",
       "0            1    TRUE                   AAA Repair             3      Low   \n",
       "1            2    TRUE  Pancreatic Resection_Cancer             1   Medium   \n",
       "\n",
       "0  Gender anesthesia diabetes severity of post procedure complications Pain  \\\n",
       "0    Male        Yes      Yes                                     High  Yes   \n",
       "1  Female        Yes       No                                      Low   No   \n",
       "\n",
       "0 recurrence of original condition  \n",
       "0                               No  \n",
       "1                               No  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####In this cell, Merging the data from the function get_procedure_attributes,function get_procedure_success with get_procedure_outcomes data, procedure_id being the primary key\n",
    "Procedure_info_outcomes = pd.merge(Procedure_info,pro_outcomes, on = ['procedure_id'], how = 'inner')\n",
    "print(Procedure_info_outcomes.shape)\n",
    "Procedure_info_outcomes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE     0.821643\n",
      "FALSE    0.178357\n",
      "Name: Outcome, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking for balance of the target. It shows the target is imbalance. I am using scale_pos_weight in xgb to remove the imbalance from the dataset\n",
    "print(Procedure_info_outcomes['Outcome'].value_counts(dropna=False, normalize=True).head())\n",
    "\n",
    "#####Visualizing the Target ( Outcome of the Procedure)\n",
    "plt.figure(figsize =(12,6));\n",
    "sns.countplot(x = 'Outcome', data = Procedure_info_outcomes);\n",
    "plt.xlabel(\"Outcome\",fontsize = 12);\n",
    "plt.ylabel(\"Frequency\",fontsize = 12);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 499 entries, 0 to 498\n",
      "Data columns (total 11 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   procedure_id                              499 non-null    int64  \n",
      " 1   Outcome                                   499 non-null    object \n",
      " 2   Procedure                                 499 non-null    object \n",
      " 3   Time in Hours                             499 non-null    float64\n",
      " 4   Severity                                  499 non-null    object \n",
      " 5   Gender                                    499 non-null    object \n",
      " 6   anesthesia                                499 non-null    object \n",
      " 7   diabetes                                  499 non-null    object \n",
      " 8   severity of post procedure complications  499 non-null    object \n",
      " 9   Pain                                      499 non-null    object \n",
      " 10  recurrence of original condition          499 non-null    object \n",
      "dtypes: float64(1), int64(1), object(9)\n",
      "memory usage: 66.8+ KB\n"
     ]
    }
   ],
   "source": [
    "####Converting the Procedure ID and Time taken for the procedure to int and float respectively.\n",
    "Procedure_info_outcomes['procedure_id'] = Procedure_info_outcomes['procedure_id'].astype(str).astype(int)\n",
    "Procedure_info_outcomes['Time in Hours'] = Procedure_info_outcomes['Time in Hours'].astype(str).astype(float)\n",
    "\n",
    "\n",
    "#####Imputing the Null values in Time(in hours) columns with the mean of that columns.\n",
    "Procedure_info_outcomes[\"Time in Hours\"] = Procedure_info_outcomes[\"Time in Hours\"].fillna(value=Procedure_info_outcomes[\"Time in Hours\"].mean())\n",
    "\n",
    "\n",
    "####Printing the info of the whole dataset\n",
    "Procedure_info_outcomes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>procedure_id</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Procedure</th>\n",
       "      <th>Time in Hours</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>anesthesia</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>severity of post procedure complications</th>\n",
       "      <th>Pain</th>\n",
       "      <th>recurrence of original condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AAA Repair</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Pancreatic Resection_Cancer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Laminectomy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>AAA Repair_Ruptured_Endovascular</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0  procedure_id  Outcome                         Procedure  Time in Hours  \\\n",
       "0             1        0                        AAA Repair            3.0   \n",
       "1             2        0       Pancreatic Resection_Cancer            1.0   \n",
       "2             3        0                       Laminectomy            1.0   \n",
       "3             4        0  AAA Repair_Ruptured_Endovascular            2.0   \n",
       "\n",
       "0 Severity  Gender anesthesia diabetes  \\\n",
       "0      Low    Male        Yes      Yes   \n",
       "1   Medium  Female        Yes       No   \n",
       "2   Medium  Female        Yes       No   \n",
       "3   Medium    Male        Yes      Yes   \n",
       "\n",
       "0 severity of post procedure complications Pain  \\\n",
       "0                                     High  Yes   \n",
       "1                                      Low   No   \n",
       "2                                      Low   No   \n",
       "3                                   Medium  Yes   \n",
       "\n",
       "0 recurrence of original condition  \n",
       "0                               No  \n",
       "1                               No  \n",
       "2                               No  \n",
       "3                              Yes  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapping the target the variable\n",
    "\n",
    "Procedure_info_outcomes['Outcome']=Procedure_info_outcomes['Outcome'].map({'TRUE': 0, 'FALSE': 1})\n",
    "Procedure_info_outcomes.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Procedure-------------------------\n",
      "                                     total   percent\n",
      "Pancreatic Resection                    33  0.066132\n",
      "Radiosurgery                            29  0.058116\n",
      "AAA Repair_Ruptured_Open                24  0.048096\n",
      "Laminectomy                             23  0.046092\n",
      "Lithotriptor                            19  0.038076\n",
      "General surgery                         18  0.036072\n",
      "Pancreatic Resection_Cancer             17  0.034068\n",
      "Amputation                              16  0.032064\n",
      "Lithotomy                               16  0.032064\n",
      "Xenotransplantation                     16  0.032064\n",
      "Ablation                                16  0.032064\n",
      "Endoscopic surgery                      15  0.030060\n",
      "Esophageal Resection                    15  0.030060\n",
      "Facial rejuvenation                     14  0.028056\n",
      "PCI                                     14  0.028056\n",
      "AAA Repair_Ruptured_Endovascular        14  0.028056\n",
      "Stereotactic surgery                    14  0.028056\n",
      "Vaginoplasty                            14  0.028056\n",
      "Laparoscopic surgery                    13  0.026052\n",
      "Biopsy                                  13  0.026052\n",
      "Knee cartilage replacement therapy      13  0.026052\n",
      "Hemilaminectomy                         13  0.026052\n",
      "AAA Repair_Un-ruptured_Open             12  0.024048\n",
      "Cardiopulmonary resuscitation           12  0.024048\n",
      "AAA Repair_Un-ruptured_Endovascular     12  0.024048\n",
      "Image-guided surgery                    12  0.024048\n",
      "AAA Repair                              11  0.022044\n",
      "Hand surgery                            10  0.020040\n",
      "Neovaginoplasty                         10  0.020040\n",
      "Procedure                                9  0.018036\n",
      "CABG                                     9  0.018036\n",
      "Lobotomy                                 8  0.016032\n",
      "Carotid Endarterectomy                   8  0.016032\n",
      "Cryosurgery                              7  0.014028\n",
      "--------------------Severity-------------------------\n",
      "        total   percent\n",
      "Medium    187  0.374749\n",
      "High      153  0.306613\n",
      "Low       127  0.254509\n",
      "NaN        32  0.064128\n",
      "--------------------Gender-------------------------\n",
      "        total   percent\n",
      "Male      261  0.523046\n",
      "Female    208  0.416834\n",
      "NaN        30  0.060120\n",
      "--------------------Anesthesia-------------------------\n",
      "     total   percent\n",
      "Yes    437  0.875752\n",
      "No      62  0.124248\n",
      "--------------------Diabetes-------------------------\n",
      "     total   percent\n",
      "Yes    247  0.494990\n",
      "No     205  0.410822\n",
      "NaN     47  0.094188\n",
      "--------------------Severity Of Post Procedure Complications-------------------------\n",
      "        total   percent\n",
      "Low       183  0.366733\n",
      "High      169  0.338677\n",
      "Medium    147  0.294589\n",
      "--------------------Pain-------------------------\n",
      "     total   percent\n",
      "Yes    236  0.472946\n",
      "No     219  0.438878\n",
      "NaN     44  0.088176\n",
      "--------------------Recurrence Of Original Condition-------------------------\n",
      "     total   percent\n",
      "No     253  0.507014\n",
      "Yes    207  0.414830\n",
      "NaN     39  0.078156\n"
     ]
    }
   ],
   "source": [
    "#Separate categorical and numerical columns\n",
    "cat_column = Procedure_info_outcomes.dtypes[Procedure_info_outcomes.dtypes == 'object']\n",
    "num_column = Procedure_info_outcomes.dtypes[Procedure_info_outcomes.dtypes != 'object']\n",
    "\n",
    "\n",
    "#####SHowing the cateogries in each columns with thier total and %\n",
    "for col in list(cat_column.index):\n",
    "    print(f\"--------------------{col.title()}-------------------------\")\n",
    "    total= Procedure_info_outcomes[col].value_counts()\n",
    "    percent = total / Procedure_info_outcomes.shape[0]\n",
    "    df = pd.concat([total,percent],keys = ['total','percent'],axis = 1)\n",
    "    print(df)\n",
    "    #print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "####As we can see from above, we have Nulls in few of the columns which are categories, You cant impute 0 or a number for categories, so imputing Not_listed for NUlls\n",
    "\n",
    "edit_columns = ['Severity', 'Gender', 'anesthesia', \n",
    "             'diabetes', 'Pain','recurrence of original condition' ]\n",
    "\n",
    "# Replace NaN with Not_Listed\n",
    "for col in edit_columns:\n",
    "    Procedure_info_outcomes.loc[Procedure_info_outcomes[col] == 'NaN', col] = 'Not_listed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in Severity: 0\n",
      "NaN in Gender: 0\n",
      "NaN in anesthesia: 0\n",
      "NaN in diabetes: 0\n",
      "NaN in Pain: 0\n",
      "NaN in recurrence of original condition: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if NAN is present\n",
    "for col in edit_columns:\n",
    "    print(f\"NaN in {col}: {Procedure_info_outcomes[(Procedure_info_outcomes[col] == 'NaN')].any().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####Visualizing the Severity category and its distrubution\n",
    "\n",
    "from scipy import interp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from matplotlib import rcParams\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fig = plt.figure(figsize=(20,4)) \n",
    "sns.countplot(y=\"Severity\", data=Procedure_info_outcomes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####Visualizing the Gender category and its distrubution\n",
    "\n",
    "plt.figure(figsize=(20,3)) \n",
    "sns.countplot(y=\"Gender\", data=Procedure_info_outcomes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####Visualizing the anesthesia category and its distrubution\n",
    "\n",
    "plt.figure(figsize=(20,3)) \n",
    "sns.countplot(y=\"anesthesia\", data=Procedure_info_outcomes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####Visualizing the diabetes category and its distrubution\n",
    "\n",
    "plt.figure(figsize=(20,3)) \n",
    "sns.countplot(y=\"diabetes\", data=Procedure_info_outcomes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once, analysis has been done from the above visualzations, we get to know about each feature distrubtion and relation to the target column. \n",
    "As I dont have many features in this dataset, I am not able to do much deeper analysis like outlier detection, \n",
    "feature selection methods( choosing top 95% important features) for model training**\n",
    "\n",
    "**I am not doing scaling on my feature set because xgboost will handle it in the model training part.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>procedure_id</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>TimeinHours</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>anesthesia</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>severityofpostprocedurecomplications</th>\n",
       "      <th>Pain</th>\n",
       "      <th>recurrenceoforiginalcondition</th>\n",
       "      <th>...</th>\n",
       "      <th>Procedure_Lobotomy</th>\n",
       "      <th>Procedure_Neovaginoplasty</th>\n",
       "      <th>Procedure_PCI</th>\n",
       "      <th>Procedure_PancreaticResection</th>\n",
       "      <th>Procedure_PancreaticResection_Cancer</th>\n",
       "      <th>Procedure_Procedure</th>\n",
       "      <th>Procedure_Radiosurgery</th>\n",
       "      <th>Procedure_Stereotacticsurgery</th>\n",
       "      <th>Procedure_Vaginoplasty</th>\n",
       "      <th>Procedure_Xenotransplantation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   procedure_id  Outcome  TimeinHours  Severity  Gender  anesthesia  diabetes  \\\n",
       "0           1.0      0.0          3.0       1.0     0.0         0.0       0.0   \n",
       "1           2.0      0.0          1.0       2.0     1.0         0.0       1.0   \n",
       "\n",
       "   severityofpostprocedurecomplications  Pain  recurrenceoforiginalcondition  \\\n",
       "0                                   0.0   0.0                            1.0   \n",
       "1                                   1.0   1.0                            1.0   \n",
       "\n",
       "   ...  Procedure_Lobotomy  Procedure_Neovaginoplasty  Procedure_PCI  \\\n",
       "0  ...                 0.0                        0.0            0.0   \n",
       "1  ...                 0.0                        0.0            0.0   \n",
       "\n",
       "   Procedure_PancreaticResection  Procedure_PancreaticResection_Cancer  \\\n",
       "0                            0.0                                   0.0   \n",
       "1                            0.0                                   1.0   \n",
       "\n",
       "   Procedure_Procedure  Procedure_Radiosurgery  Procedure_Stereotacticsurgery  \\\n",
       "0                  0.0                     0.0                            0.0   \n",
       "1                  0.0                     0.0                            0.0   \n",
       "\n",
       "   Procedure_Vaginoplasty  Procedure_Xenotransplantation  \n",
       "0                     0.0                            0.0  \n",
       "1                     0.0                            0.0  \n",
       "\n",
       "[2 rows x 44 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying label encoding to Severity, severity of post procedure complications as this columns induces order/precedence\n",
    "\n",
    "from sklearn import preprocessing \n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "Procedure_info_outcomes['Severity']= label_encoder.fit_transform(Procedure_info_outcomes['Severity']) \n",
    "Procedure_info_outcomes['severity of post procedure complications']= label_encoder.fit_transform(Procedure_info_outcomes['severity of post procedure complications']) \n",
    "   \n",
    "\n",
    "####Mapping the other columns which either Yes or No\n",
    "Procedure_info_outcomes['Gender']=Procedure_info_outcomes['Gender'].map({'Male': 0, 'Female': 1, 'Not_listed' : 99})\n",
    "Procedure_info_outcomes['anesthesia']=Procedure_info_outcomes['anesthesia'].map({'Yes': 0, 'No': 1,'Not_listed' : 99})\n",
    "Procedure_info_outcomes['diabetes']=Procedure_info_outcomes['diabetes'].map({'Yes': 0, 'No': 1,'Not_listed' : 999})\n",
    "Procedure_info_outcomes['recurrence of original condition']=Procedure_info_outcomes['recurrence of original condition'].map({'Yes': 0, 'No': 1,'Not_listed' : 99})\n",
    "Procedure_info_outcomes['Pain']=Procedure_info_outcomes['Pain'].map({'Yes': 0, 'No': 1,'Not_listed' : 99})\n",
    "\n",
    "\n",
    "\n",
    "####Doing one-hot encoding for Procedure. Having Procedure as a feature will help the model understand the which procedure has more chances of success or failure\n",
    "Procedure_info_outcomes_final = pd.concat([Procedure_info_outcomes,pd.get_dummies(Procedure_info_outcomes['Procedure'],prefix = 'Procedure')], axis =1 )\n",
    "\n",
    "\n",
    "#### Cleaning the column names and dropping procedure as we did OHE on procedure column\n",
    "import re\n",
    "Procedure_info_outcomes_final = Procedure_info_outcomes_final.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "Procedure_info_outcomes_final = Procedure_info_outcomes_final.drop(['Procedure'], axis =1)\n",
    "\n",
    "Procedure_info_outcomes_final = Procedure_info_outcomes_final.astype(float)\n",
    "Procedure_info_outcomes_final.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 43)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####I am using train_test_split to seperate my main test data mimicking as a unseen data(future data) from the dataset. \n",
    "#####I have my train dataset on which I do model training and cv etc.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(Procedure_info_outcomes_final, test_size=0.25)\n",
    "\n",
    "X_train = train.drop(['Outcome'], axis =1)\n",
    "y_train = train['Outcome'].copy()\n",
    "\n",
    "X_test = test.drop('Outcome', axis =1)\n",
    "\n",
    "####I have 125 records as my unseen test data on which I will be predicting\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####Below code is for Hyper parameter tuning using Hyperopt. \n",
    "#####I have tried lightgbm with bayesian optimization but it didnt fetch good results, so sticking with Hyperopt and XGB\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, anneal, Trials,STATUS_OK\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "n_iter=300       ###Number of iterations the optimization function will run for\n",
    "random_state=10  ###Setting the state of the function\n",
    "num_folds=12     ###Number of folds for CV\n",
    "\n",
    "kf = KFold(n_splits=num_folds)  ### I am using KFold cross validation\n",
    "NFOLDS = 12  ##Number of folds\n",
    "def score(params, random_state=random_state, cv=kf, X=X_train, y=y_train):\n",
    "    # the function gets a set of variable parameters in \"params\"\n",
    "    params = {\n",
    "             'colsample_bytree': int(params['colsample_bytree']),\n",
    "             'max_depth': int(params['max_depth']),\n",
    "             'lambda':params['lambda'],\n",
    "             'gamma': params['gamma'],\n",
    "             'scale_pos_weight' : 0.219,                      ###for the imblance of the target variable\n",
    "            'objective' : 'binary:logistic',                  ###for classification\n",
    "             'min_child_weight' : int(params['min_child_weight']),\n",
    "             'eta': params['eta'],\n",
    "             'n_estimators': int(params['n_estimators'])}\n",
    "    model = xgb.XGBClassifier(random_state=random_state, **params,verbose_eval=200, early_stopping_rounds=50, stratified=True) \n",
    "    ###Used stratified = True for each distribution of target in each fold.\n",
    "   \n",
    "    # and then conduct the cross validation with the same folds as before\n",
    "    accuracies  = -cross_val_score(model, X, y, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "    \n",
    "    CrossValMean = accuracies.mean()\n",
    "\n",
    "    print(\"CrossValMean:\", CrossValMean)\n",
    "\n",
    "    return{'loss':1-CrossValMean, 'status': STATUS_OK } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValMean:                                          \n",
      "-0.7837567833401166                                    \n",
      "CrossValMean:                                                                    \n",
      "-0.7923339777506445                                                              \n",
      "CrossValMean:                                                                    \n",
      "-0.8120386480803147                                                              \n",
      "CrossValMean:                                                                    \n",
      "-0.7923339777506445                                                              \n",
      "CrossValMean:                                                                    \n",
      "-0.8083547008547008                                                              \n",
      "CrossValMean:                                                                    \n",
      "-0.7924772758106092                                                              \n",
      "CrossValMean:                                                                    \n",
      "-0.5                                                                             \n",
      "CrossValMean:                                                                    \n",
      "-0.7923339777506445                                               \n",
      "CrossValMean:                                                     \n",
      "-0.7501966320716321                                               \n",
      "CrossValMean:                                                     \n",
      "-0.5                                                              \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.8114862298195632                                                \n",
      "CrossValMean:                                                      \n",
      "-0.8076086182336183                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.796551689051689                                                 \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7949932166598832                                                \n",
      "CrossValMean:                                                      \n",
      "-0.8075213675213675                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7498137973137973                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7917833401166733                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7837567833401166                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7674699837199838                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.746727377560711                                                 \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7949932166598832                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7449912664495998                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.8006673110839778                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7735751594084928                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7707392144892146                                                \n",
      "CrossValMean:                                                      \n",
      "-0.8014129697463029                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7949932166598832                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7674699837199838                                                \n",
      "CrossValMean:                                                      \n",
      "-0.807968898385565                                                 \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7674699837199838                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7822135734635735                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7401093813593814                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7289370506037174                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5892791005291005                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.8063252950752952                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7805469067969066                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7578451024284357                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.8075213675213675                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7949932166598832                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7982030932030931                                                \n",
      "CrossValMean:                                                      \n",
      "-0.591007495590829                                                 \n",
      "CrossValMean:                                                      \n",
      "-0.7923339777506445                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7561784357617691                                                \n",
      "CrossValMean:                                                      \n",
      "-0.5                                                               \n",
      "CrossValMean:                                                      \n",
      "-0.7416525912359248                                                \n",
      "CrossValMean:                                                      \n",
      "-0.7937537308370642                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7674699837199838                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7944812440645773                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7514804639804639                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7386212861212863                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.657347035680369                                                  \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5094444444444445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.808076923076923                                                  \n",
      "CrossValMean:                                                       \n",
      "-0.7805469067969066                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7837567833401166                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.718949599782933                                                  \n",
      "CrossValMean:                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7674699837199838                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7578451024284357                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5957605820105821                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7561784357617691                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5094444444444445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7997463030796363                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7822135734635735                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7578451024284357                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7658674196174196                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7965364265364264                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7814763091846425                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7416525912359248                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7951475376475376                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.8006673110839778                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7724058811558812                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7961479107312441                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.737078076244743                                                  \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.791394824311491                                                  \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.8076911206077871                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7517784221950888                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7674699837199838                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7674699837199838                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.8075213675213675                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7545117690951025                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7750530796364131                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7865871320037986                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7578451024284357                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.551470458553792                                                  \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7692388244471577                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5094444444444445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7416525912359248                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.8073516144349479                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7712228666395333                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7626575430742096                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7578451024284357                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7626575430742096                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7643242097408763                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.788692680776014                                                  \n",
      "CrossValMean:                                                       \n",
      "-0.7805469067969066                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7595117690951025                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7416525912359248                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.6260163139329805                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7933265499932166                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7416525912359248                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.8083547008547008                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.808076923076923                                                  \n",
      "CrossValMean:                                                       \n",
      "-0.7674699837199838                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5094444444444445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7940055623388956                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5412301587301588                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7401093813593814                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.8014129697463029                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7576456722290055                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.6714562135395469                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.6876456722290056                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7822135734635735                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5412301587301588                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.8069349477682812                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.8068445597612265                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7976360059693394                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.6108223104056437                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5403527336860671                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.808076923076923                                                  \n",
      "CrossValMean:                                                       \n",
      "-0.7773417785917786                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.737078076244743                                                  \n",
      "CrossValMean:                                                       \n",
      "-0.718949599782933                                                  \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.7416525912359248                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.591007495590829                                                  \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.814756732465066                                                  \n",
      "CrossValMean:                                                       \n",
      "-0.7643242097408763                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.6812947700447701                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.809542972459639                                                  \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "CrossValMean:                                                       \n",
      "-0.5798897707231041                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7674699837199838                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5771494708994709                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7923339777506445                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.7234237213403881                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.8095275403608736                                                 \n",
      "CrossValMean:                                                       \n",
      "-0.5                                                                \n",
      "100%|██████████| 300/300 [01:44<00:00,  2.87trial/s, best loss: 1.5]\n",
      "{'colsample_bytree': 0.6000000000000001, 'eta': 0.16, 'gamma': 0.5, 'lambda': 1.8, 'max_depth': 27.0, 'min_child_weight': 28.0, 'n_estimators': 176.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6000000000000001,\n",
       " 'eta': 0.16,\n",
       " 'gamma': 0.5,\n",
       " 'lambda': 1.8,\n",
       " 'max_depth': 27,\n",
       " 'min_child_weight': 28.0,\n",
       " 'n_estimators': 176}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spacefor hyperopt\n",
    "space={\n",
    "  \n",
    "       'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1,0.1),\n",
    "       'gamma': hp.quniform('gamma', 0, 1,0.1),\n",
    "       'lambda': hp.quniform('lambda', 1, 2,0.1),\n",
    "       'min_child_weight' : hp.quniform('min_child_weight', 1, 30, 1),\n",
    "       'eta': hp.quniform('eta', 0.01, 0.2,0.01),\n",
    "       'max_depth' : hp.quniform('max_depth', 2, 30, 1),\n",
    "       'n_estimators' : hp.quniform('n_estimators', 30, 200, 1)\n",
    " \n",
    "      }\n",
    "\n",
    "\n",
    "###Running the fmin function\n",
    "best = fmin(fn=score,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=n_iter, # maximum number of iterations\n",
    "            #max_concurrent=10, # logging\n",
    "            rstate=np.random.RandomState(random_state))\n",
    " \n",
    "    \n",
    "#printing the best params from hyperopt\n",
    "print(best)\n",
    "\n",
    "#params from the best\n",
    "params = {'colsample_bytree': (best['colsample_bytree']),\n",
    "                 'eta': best['eta'],\n",
    "                 'gamma': best['gamma'],\n",
    "                 'lambda': best['lambda'],\n",
    "                 'max_depth': int(best['max_depth']),\n",
    "                 'min_child_weight': best['min_child_weight'],\n",
    "                 'n_estimators':int(best['n_estimators'])}\n",
    "###Getting the best params from the Hyperopt\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second script the running the trained model and predict on the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:42:20] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tdtrain_again-rmse:0.46699\tdvalid_again-rmse:0.46711\n",
      "Multiple eval metrics have been passed: 'dvalid_again-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid_again-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[63]\tdtrain_again-rmse:0.30813\tdvalid_again-rmse:0.32817\n",
      "\n",
      "Fold 1 | ROC_AUC: 0.8074074074074075\n",
      "[17:42:20] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tdtrain_again-rmse:0.46752\tdvalid_again-rmse:0.46571\n",
      "Multiple eval metrics have been passed: 'dvalid_again-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid_again-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[18]\tdtrain_again-rmse:0.31014\tdvalid_again-rmse:0.29465\n",
      "\n",
      "Fold 2 | ROC_AUC: 0.9111111111111111\n",
      "[17:42:20] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tdtrain_again-rmse:0.46630\tdvalid_again-rmse:0.47133\n",
      "Multiple eval metrics have been passed: 'dvalid_again-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid_again-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[70]\tdtrain_again-rmse:0.30661\tdvalid_again-rmse:0.34995\n",
      "\n",
      "Fold 3 | ROC_AUC: 0.8200000000000001\n",
      "[17:42:20] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tdtrain_again-rmse:0.46682\tdvalid_again-rmse:0.46957\n",
      "Multiple eval metrics have been passed: 'dvalid_again-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid_again-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[12]\tdtrain_again-rmse:0.31397\tdvalid_again-rmse:0.34851\n",
      "\n",
      "Fold 4 | ROC_AUC: 0.7533333333333334\n",
      "[17:42:20] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tdtrain_again-rmse:0.46676\tdvalid_again-rmse:0.46628\n",
      "Multiple eval metrics have been passed: 'dvalid_again-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid_again-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[24]\tdtrain_again-rmse:0.31434\tdvalid_again-rmse:0.28047\n",
      "\n",
      "Fold 5 | ROC_AUC: 0.9538461538461538\n",
      "[17:42:20] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tdtrain_again-rmse:0.46682\tdvalid_again-rmse:0.46957\n",
      "Multiple eval metrics have been passed: 'dvalid_again-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid_again-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[12]\tdtrain_again-rmse:0.31656\tdvalid_again-rmse:0.34771\n",
      "\n",
      "Fold 6 | ROC_AUC: 0.8366666666666667\n",
      "[17:42:20] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tdtrain_again-rmse:0.46742\tdvalid_again-rmse:0.46622\n",
      "Multiple eval metrics have been passed: 'dvalid_again-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid_again-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[28]\tdtrain_again-rmse:0.30466\tdvalid_again-rmse:0.26952\n",
      "\n",
      "Fold 7 | ROC_AUC: 0.9615384615384616\n",
      "[17:42:20] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tdtrain_again-rmse:0.46562\tdvalid_again-rmse:0.47156\n",
      "Multiple eval metrics have been passed: 'dvalid_again-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid_again-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[60]\tdtrain_again-rmse:0.30079\tdvalid_again-rmse:0.36204\n",
      "\n",
      "Fold 8 | ROC_AUC: 0.7666666666666666\n",
      "[17:42:20] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tdtrain_again-rmse:0.46621\tdvalid_again-rmse:0.47296\n",
      "Multiple eval metrics have been passed: 'dvalid_again-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid_again-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[16]\tdtrain_again-rmse:0.30634\tdvalid_again-rmse:0.36291\n",
      "\n",
      "Fold 9 | ROC_AUC: 0.8482142857142857\n",
      "[17:42:20] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tdtrain_again-rmse:0.46804\tdvalid_again-rmse:0.46078\n",
      "Multiple eval metrics have been passed: 'dvalid_again-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid_again-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[64]\tdtrain_again-rmse:0.30721\tdvalid_again-rmse:0.26082\n",
      "\n",
      "Fold 10 | ROC_AUC: 0.9047619047619048\n",
      "[17:42:20] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tdtrain_again-rmse:0.46802\tdvalid_again-rmse:0.46291\n",
      "Multiple eval metrics have been passed: 'dvalid_again-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid_again-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[11]\tdtrain_again-rmse:0.32089\tdvalid_again-rmse:0.32750\n",
      "\n",
      "Fold 11 | ROC_AUC: 0.8148148148148149\n",
      "[17:42:20] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tdtrain_again-rmse:0.46682\tdvalid_again-rmse:0.46957\n",
      "Multiple eval metrics have been passed: 'dvalid_again-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid_again-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[14]\tdtrain_again-rmse:0.30923\tdvalid_again-rmse:0.35446\n",
      "\n",
      "Fold 12 | ROC_AUC: 0.7633333333333334\n"
     ]
    }
   ],
   "source": [
    "####Now as we have the best params from the above hyperopt optimization function, we use these best params and run a manual CV and fit it on our train set.\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "train = xgb.DMatrix(X_train)\n",
    "folds = KFold(n_splits=NFOLDS)\n",
    "columns = X_train.columns\n",
    "splits = folds.split(X_train, y_train)\n",
    "y_preds = np.zeros(X_test.shape[0])\n",
    "y_oof = np.zeros(X_train.shape[0])\n",
    "score = 0\n",
    "\n",
    "####Manual CV\n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "    X_train_again, X_valid_again = X_train[columns].iloc[train_index], X_train[columns].iloc[valid_index]\n",
    "    y_train_again, y_valid_again = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "    dtrain_again = xgb.DMatrix(X_train_again, label=y_train_again)\n",
    "    dvalid_again = xgb.DMatrix(X_valid_again,label=y_valid_again)\n",
    "    watchlist = [(dtrain_again, 'dtrain_again'), (dvalid_again, 'dvalid_again')]\n",
    "    clf = xgb.train(params, dtrain_again,int(best['n_estimators']),  verbose_eval=200, early_stopping_rounds=50,evals = watchlist)\n",
    "    y_pred_valid = clf.predict(xgb.DMatrix(X_valid_again))\n",
    "    y_oof[valid_index] = y_pred_valid\n",
    "    print(f\"Fold {fold_n + 1} | ROC_AUC: {roc_auc_score(y_valid_again, y_pred_valid)}\")\n",
    "    score += roc_auc_score(y_valid_again, y_pred_valid) / NFOLDS\n",
    "    #y_preds is on test dataset\n",
    "    y_preds += clf.predict(xgb.DMatrix(X_test)) / NFOLDS\n",
    "    ###Getting the index of the X_test, as it would be easy to join the test dataset later on.\n",
    "    valid_individual_test=pd.DataFrame()\n",
    "    valid_individual_test['val_idx']=X_test.index\n",
    "    valid_individual_test['pred']=y_preds\n",
    "###Pred_main is our final dataframe with the predictions as asked in the problem statement.\n",
    "pred_main = valid_individual_test.set_index('val_idx')\n",
    "    \n",
    "\n",
    "####Below you can see the ROC_AUC score for each fold in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>procedure_id</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>357.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.304560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     procedure_id  Outcome      pred\n",
       "6             7.0      0.0  0.023622\n",
       "356         357.0      1.0  0.304560\n",
       "212         213.0      0.0  0.041198"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Joining the predictions with the test dataset based on index.\n",
    "\n",
    "test_df = test[['procedure_id','Outcome']]\n",
    "test_df = pd.merge(test_df, pred_main, left_index= True, right_index = True)\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.824"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Accuracy on the Unseen data is 82.4% \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_df.pred = test_df.pred.round()\n",
    "accuracy = accuracy_score(test_df['Outcome'], test_df['pred'])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUTURE SCOPE:**\n",
    "\n",
    "1. Do feature engineering, Create more features, so that model would understand better and get better accuracy.\n",
    "2. Run feature selection methods to get top 95% features as it removes nosie from the dataset.\n",
    "3. Check for outliers. I would keep the outlier in the dataset as it would create more robustness of the model because if we drop the outliers and if unseen data has outliers, then our model has never seen outliers. It would underfit the data.\n",
    "4. Run various optimzation methods like optuna, bayesian and run various algorithms like lightgbm, catboost. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
